{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version: 1.42.0\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "print(f'openai version: {openai.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_response_model, get_response_usage, get_response_content, get_response_cost, get_response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_model(response):\n",
    "    return response.model\n",
    "def get_response_usage(response):\n",
    "    return response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "def get_response_content(response):\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_cost(response):\n",
    "    pricing_units = 1e6\n",
    "    pricing = {'gpt-4o': (5.0, 15.0),\n",
    "               'gpt-4o-2024-08-06': (2.5, 10.0),\n",
    "               'gpt-4o-2024-05-13': (5.0, 15.0),\n",
    "               'gpt-4o-mini': (0.150, 0.600),\n",
    "               'gpt-4o-mini-2024-07-18': (0.150, 0.600),\n",
    "               'chatgpt-4o-latest': (5.00, 15.00),\n",
    "               'gpt-4-turbo': (10.00, 30.00),\n",
    "               'gpt-4-turbo-2024-04-09': (10.00, 30.00),\n",
    "               'gpt-4': (30.00, 60.00),\n",
    "               'gpt-4-32k': (60.00, 120.00),\n",
    "               'gpt-4-0125-preview': (10.00, 30.00),\n",
    "               'gpt-4-1106-preview': (10.00, 30.00),\n",
    "               'gpt-4-vision-preview': (10.00, 30.00),\n",
    "               'gpt-3.5-turbo-0125': (0.50, 1.50),\n",
    "               'gpt-3.5-turbo-instruct': (1.50, 2.00),\n",
    "               'gpt-3.5-turbo-1106': (1.00, 2.00),\n",
    "               'gpt-3.5-turbo-0613': (1.50, 2.00),\n",
    "               'gpt-3.5-turbo-16k-0613': (3.00, 4.00),\n",
    "               'gpt-3.5-turbo-0301': (1.50, 2.00),\n",
    "               'davinci-002': (2.00, 2.00),\n",
    "               'babbage-002': (0.40, 0.40)\n",
    "               }\n",
    "    \n",
    "    model = get_response_model(response)\n",
    "    input_tokens, output_tokens = get_response_usage(response)\n",
    "\n",
    "    input_rate, output_rate = pricing[model]\n",
    "    input_cost = (input_tokens/pricing_units) * input_rate\n",
    "    output_cost = (output_tokens/pricing_units) * output_rate\n",
    "\n",
    "    return input_cost + output_cost\n",
    "\n",
    "def get_response_metadata(response, verbose=True):\n",
    "    model = get_response_model(response)\n",
    "    input_tokens, output_tokens = get_response_usage(response)\n",
    "    cost = get_response_cost(response)\n",
    "    return model, (input_tokens, output_tokens), cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what is the most recent thing you know?\"\n",
    "        },\n",
    "    ],\n",
    "    n=1,\n",
    "    max_tokens=None,\n",
    "    response_format={'type': 'text'},\n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response metadata:\n",
      "model = gpt-4o-2024-05-13\n",
      "input tokens = 26\n",
      "output tokens = 29\n",
      "cost = $0.0006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokens, cost = get_response_metadata(response)\n",
    "print((f'Response metadata:\\n' +\n",
    "       f'model = {model}\\n' + \n",
    "       f'input tokens = {tokens[0]}\\n' +\n",
    "       f'output tokens = {tokens[1]}\\n' +\n",
    "       f'cost = ${cost:.4f}\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in October 2023, the most recent events would be up-to-date within that timeframe. If you're looking for information on a specific topic or event, please let me know, and I can provide the latest information I have.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
